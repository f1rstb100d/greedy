# 为什么深度学习难训练
```
会存在梯度消失，导致第一层的变量改变不了

解决方法：
1. layer-wise pretraing
2. activation function
3. better optimization
4. larger data
layer-wise pretraing是指在初始化的时候，利用RBM或者autoencoder得到输入层和第一层隐藏层之间的参数w1和b1，同时得到第一个隐藏层的结果h1，然后同样利用RBM和autoencoder得到第一个隐藏层和第二个隐藏层之间的参数w2和b2，以及第二层隐藏层的结果h2
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Deep%20Learning%20hard%20to%20train.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/layer-wise%20pretraing.jpg)

# Dropout
```
解决过拟合的方法：
1. 加正则L1/L2
2. early stopping
3. 加噪声 dropout
dropout是指在计算完这一层所有节点的h(x)后，根据超参数p=0.5，将其中50%的h(x)改为0然后继续后面的计算。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Dropout.jpg)

# Multimodal Learning
```
端到端的翻译：RNN/LSTM(中文)->中间encoder向量->RNN/LSTM(英文)    翻译
CNN(图片) -> 中间encoder向量 -> RNN/LSTM(text)    看图说话Image caption
RNN/LSTM(text) -> 中间encoder向量 -> CNN(image)
```

# Seq2Seq模型
```
通过一个LSTM模型，把中文句子转换成一个向量meaning vector，通过这个向量生成一个英文句子，本质上这个英文句子encoding之后在这个空间里也是这个向量。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Seq2Seq%20model.jpg)

```
怎么判断预测的效果好不好？
预测值为y^，真实值是y，分别统计unigram出现的次数为3，bi-gram(两两一队同时出现)出现的次数2，tri-gram出现的次数为1，发现比下面那个y^要好很多。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Seq2Seq%E6%95%88%E6%9E%9C%E5%88%A4%E5%88%AB.jpg)

```
如果我不想每次的softmax预测单词只取可能性最高的那个
解决方法1：exhausted search，即每个位置存在的单词有|V|种可能，遍历出这些单词所有的可能的组合，求出效果最好的句子作为翻译结果。
解决方法2：Beam Search，假设beam的参数k=3，从<start>开始，先预测出3个可能性最高的单词，然后在每个单词的基础上预测下一个单词，每个有Top3种选择，一共9种选择。统计出两次log p(the|<start>)+log p(today|the)和最大的Top3种可能。然后利用这个三个排列，每一个排列再选出Top3的可能单词，一共又产生9种选项，再筛选。直到预测出<end>结束。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Exhaustic%20Search.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Beam%20Search.jpg)

# Attention(注意力机制)
```
1. Attention for Image Captioning

传统的看图说话，不用attention：
将图片卷积之后提取出的向量，每次都输入到RNN的隐藏层中，同时修改每个RNN核心的计算函数。直到生成出<end>

利用attention的看图说话：
将图片通过CNN模型转换成3*3的矩阵，矩阵中每一块是个D维的向量，所以整个矩阵是3*3*D的向量。将图片矩阵通过f函数生成h0矩阵。
再通过f'函数将h0转换成注意力矩阵a1，a1可以看作图片矩阵每块的权重，权重大的注意力就高。利用a1和原图矩阵得到z1.
将传统的RNN两个输入扩展为3个输入，y1和d1还是还是原来的含义输入的单词和输出的每个单词的概率，同时输出一个a2作为下一次的注意力权重。
将a2带入下一次计算同样产生一个a3.
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D3.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D4.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D5.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D7.jpg)

```
2. Attention for Machine Translation
```
```
3. Self-Attention
```