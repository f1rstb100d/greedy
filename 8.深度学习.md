# 为什么深度学习难训练
```
会存在梯度消失，导致第一层的变量改变不了

解决方法：
1. layer-wise pretraing
2. activation function
3. better optimization
4. larger data
layer-wise pretraing是指在初始化的时候，利用RBM或者autoencoder得到输入层和第一层隐藏层之间的参数w1和b1，同时得到第一个隐藏层的结果h1，然后同样利用RBM和autoencoder得到第一个隐藏层和第二个隐藏层之间的参数w2和b2，以及第二层隐藏层的结果h2
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Deep%20Learning%20hard%20to%20train.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/layer-wise%20pretraing.jpg)

# Dropout
```
解决过拟合的方法：
1. 加正则L1/L2
2. early stopping
3. 加噪声 dropout
dropout是指在计算完这一层所有节点的h(x)后，根据超参数p=0.5，将其中50%的h(x)改为0然后继续后面的计算。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Dropout.jpg)

# Multimodal Learning
```
端到端的翻译：RNN/LSTM(中文)->中间encoder向量->RNN/LSTM(英文)    翻译
CNN(图片) -> 中间encoder向量 -> RNN/LSTM(text)    看图说话Image caption
RNN/LSTM(text) -> 中间encoder向量 -> CNN(image)
```

# Seq2Seq模型
```
通过一个LSTM模型，把中文句子转换成一个向量meaning vector，通过这个向量生成一个英文句子，本质上这个英文句子encoding之后在这个空间里也是这个向量。
通常传入的训练数据每个句子之间的长度是不同的，一般会选择最长的句子构造Seq2Seq，然后对那些短句子后面添加补充位构成长度一样的，再输入到Seq2Seq模型中训练。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Seq2Seq%20model.jpg)

```
怎么判断预测的效果好不好？
预测值为y^，真实值是y，分别统计unigram出现的次数为3，bi-gram(两两一队同时出现)出现的次数2，tri-gram出现的次数为1，发现比下面那个y^要好很多。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Seq2Seq%E6%95%88%E6%9E%9C%E5%88%A4%E5%88%AB.jpg)

```
如果我不想每次的softmax预测单词只取可能性最高的那个
解决方法1：exhausted search，即每个位置存在的单词有|V|种可能，遍历出这些单词所有的可能的组合，求出效果最好的句子作为翻译结果。
解决方法2：Beam Search，假设beam的参数k=3，从<start>开始，先预测出3个可能性最高的单词，然后在每个单词的基础上预测下一个单词，每个有Top3种选择，一共9种选择。统计出两次log p(the|<start>)+log p(today|the)和最大的Top3种可能。然后利用这个三个排列，每一个排列再选出Top3的可能单词，一共又产生9种选项，再筛选。直到预测出<end>结束。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Exhaustic%20Search.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Beam%20Search.jpg)

# Attention(注意力机制)
```
1. Attention for Image Captioning

传统的看图说话，不用attention：
将图片卷积之后提取出的向量，每次都输入到RNN的隐藏层中，同时修改每个RNN核心的计算函数。直到生成出<end>

利用attention的看图说话：
将图片通过CNN模型转换成3*3的矩阵，矩阵中每一块是个D维的向量，所以整个矩阵是3*3*D的向量。将图片矩阵通过f函数生成h0矩阵。
再通过f'函数将h0转换成注意力矩阵a1，a1可以看作图片矩阵每块的权重，权重大的注意力就高。利用a1和原图矩阵得到z1.
将传统的RNN两个输入扩展为3个输入，y1和d1还是还是原来的含义输入的单词和输出的每个单词的概率，同时输出一个a2作为下一次的注意力权重。
将a2带入下一次计算同样产生一个a3.
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D3.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D4.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D5.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E7%9C%8B%E5%9B%BE%E8%AF%B4%E8%AF%9D7.jpg)

```
2. Attention for Machine Translation
Seq2Seq的attention：挨个输入每个单词的pre-train(Word2vec或者Glove生成的)的向量，利用RNN得到最后一个单词的向量，也就是整合了整个句子的向量。然后在decoder处，先将输入的单词<start>和向右的数据计算出h1，然后将h1和之前encoder的每个g计算乘积得到4个数，然后计算均一化(右上角)，直接除总和也行，使用softmax均一化也行。均一化的4个数可以看作每个g的权重，然后分别相乘(左上角)得到c1'。将c1'和h1拼接看作新的h1，然后和原来一样计算softmax的y1^得到每个单词的可能性概率分布，就可以选择概率最高的那个单词了。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Seq2Seq%E7%9A%84Attention.jpg)
```
3. Self-Attention
Transformer -> Encoder -> Self-Attention
Self-Attention：先通过预训练或者上一个encoder得到单词的向量x1，然后根据3个参数矩阵Wq,Wk,Wv和x1的乘积得到q1,k1,v1。其他每个单词都做同样的操作。然后针对单词1，计算q1和其他每个单词k的乘积作为这个单词对单词1的影响力，显然自己对自己的影响力最大。然后将每个score都除以sqrt(dk)，dk是embedding dimension，这是64，所以所有score同时除以8。再利用softmax均一化上面求得的值作为这个单词对单词1的均一化影响力。然后把每个单词的影响力和这个单词的v相乘最后求和得到单词1的最终embedding向量z1.

因为Self-Attention计算了每个单词对当前单词的影响力，所以不存在LSTM的long-term dependency，即太长的句子忘了前面的。
不像LSTM的只能串行执行，Self-Attention里面的好多步可以并行执行。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Transformer1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Transformer2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Transformer3.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Transformer4.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Transformer5.jpg)

# Bert
```
基于LSTM的情感分析是按照LSTM的格式从左往右输入句子，然后再最后一个单词输入完了，得到的整个句子的context vector，加上个分类器做情感分类。
基于LSTM的语言模型，也是从左往右输入单词，但是存在一个问题，就是上文不会知道下文发生了什么，只能单向传递信息。
所以ELmo使用了双向LSTM，但是两个LSTM是独立的，从左往右的LM1产生一个context vector1，同理从右往左的LM2产生一个context vector2，然后把两个vector拼接起来concatenate得到整个句子完整的向量表示。
如果是Fully Bidirectional context embedding，就是两个LSTM模块之间同时存在往左的和往右的箭头，导致了一个问题，从左往右的还正常，从右往左的时候这次的输出值只要输出上次的输入值就行了，模型根本就没训练好，相当于有泄露，自己能看到自己。

Bert使用了Mask机制，对输入的句子随机把一些单词改成[mask]，然后输出的时候也不判断每个单词输出预测的loss了，就判断mask的这几个单词能不能还输出自己输出正确，使用交叉熵判断模型的预测效果。
Mask机制：
1. [Mask] ->  预测(天气)  80%    有80%可能完全mask这个单词，然后要去预测这个位置应该是什么单词
2. 天气  ->  预测(天气)  10%    有10%可能没有任何输入变化，还要输出同一个单词
3. 天气->[适合]  -> 预测(天气)  10%    有10%可能性这个单词被随机改成了其他单词，要还原出原来的单词

句首添加[CLS]标签，然后句子中随机改为[MASK]，句子和句子中间添加[SEP]，输入bert。输出每个单词的embedding。法一笨方法是忽略所有的标签输入，将所有单词的embedding进行Average/Max pooling然后放入分类器进行情感分类。法二是对[CLS]这个的embedding向量套上个分类器进行情感分类，[CLS]的embedding看作句子的context vector。
另外在[CLS]的embedding后面再套上个全连接层和softmax构造个分类器，可以根据原文中句子B是否在句子A紧跟着后面将label标记成0或1，通过监督学习得到个loss1。同时[MASK]单词的预测可以得到个loss2。loss1+loss2就是整个模型的loss，也就是在一个pre-train模型的基础上继续训练的过程。
bert的input是由token embedding和position embedding和segment embedding一起构成的，将单词转换成3个embedding的和。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/bert.jpg)

# 主题模型
```
将许多个文档直接输入LDA，然后定义个k=4，类似于K-means的分4类，无监督的，不知道是哪4类。
然后LDA对每个文档产生一个每一种可能归类的概率分布。
以及针对词库所有单词|V|，每一类包含哪些单词的统计表格，然后人工去观察哪些单词含量高，人工定义这一类属于什么类别。
最后就可以利用单词的统计结果把预测的分类概率转换成特征向量，然后利用逻辑回归SVM进行分类
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8BLDA.jpg)