# 数据结构
```
哈希表：传统按顺序遍历list是O(N)，把list里面每个值经过哈希运算得到索引编号，当再给定新的元素要去找的时候，先经过那个定义的哈希运算得到了它的索引编号，从而直接从list中拿出来，时间复杂度是O(1)。# Leetcode 242 15
搜索树：二叉树，对于每个节点，节点的左子树只包含小于当前节点的数，其右子树只包含大于当前节点的数。# Leetcode 98 22
堆：堆一定是一个完全二叉树(缺失元素只能是右子树，右下角元素)，最大堆是每个节点都比其子树所有节点大，最小堆是每个节点都比其子树所有节点小。 # Leetcode 347
```

# 交叉验证 cv Cross-Validation
```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

parameters = {'C':[0.001,0.01,0.1,0.5,1,2,5,10]}
lr = LogisticRegression
lr.fit(X_train,y_train).score(X_test,y_test)

clf = GridSearchCV(lr, parameters, cv=5)
clf.fit(X_train,y_train)
clf.score(X_test,y_test)
print(clf.best_params_)
```
```
以cv=5为例，对lamda可选的任何一个值，相当于给定lamda然后计算模型参数w和b，然后把这个模型用验证集计算准确率，重复5次计算一下5折交叉验证的准确率，取平均得到这个lamda的准确率，最后返回出准确率最高的那个超参数值，然后后续训练模型的参数时就可以人工指定这个超参数了
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.jpg)

# L2正则的作用
```
w1: minimize f(w1)  无正则
w2: minimize f(w2)+lamda||w2||2^2  有正则
w1的参数可选择范围为整个大参数空间，而w2仅被限制到了参数空间的一小部分
所以一定有f(w1)<=f(w2)，即w1更有可能找到更好的参数使得f结果更小
但不一定是越小越好，有可能存在过拟合
添加正则是防止过拟合的一种手段
```

# Grid Search
```
当同时使用L1-norm和L2-norm，就会有两个超参数lamda1和lamda2，两个超参数分别有一个各自的候选集，使用网格搜索遍历所有lamda1和lamda2的组合，使用交叉验证找到最好的(lamda1,lamda2)组合

除了Grid Search，其他一些参数搜索的方法：
1. 随机搜索(Random Search):超参数的可选项是一个范围，随机从范围中选出一个值作为这个超参数，然后把多个超参数组合作为这次交叉验证的参数。可以uniform等概率随机选择，也可以设定一个分布来随机选择超参数
2. 遗传算法(Genetic/Evolutionary Algorithm):若当前lamda值效果挺好的，那么下一个值就继承部分属性(遗传因子)；若效果不好就抛弃这个值
3. 贝叶斯优化(Bayesian Optimization):不断通过观测值调整先验概率，从而调整后验概率
```

# MLE与MAP
```
MLE(最大似然估计):仅通过观测值预测最好的参数theta
MAP(最大后验估计):通过观测值和先验概率去预测最好的参数theta
例：扔不规则硬币，扔了1w次，所以有可能先验概率(别人告我的概率)是不准确的，我可能会完全不相信，就看这1w次正反面得最后的概率
随着样本的增加，MLE比MAP更可信
当样本数据非常多的时候，MAP的解更趋近于MLE的解，因为先验概率在总和的占比原来越小，影响也就越来越小
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/MLE%E4%B8%8EMAP%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F.jpg)
```
假设先验概率为高斯分布正态分布，化简后目标函数后面出现L2-norm
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E9%AB%98%E6%96%AF%E5%85%88%E9%AA%8C%E5%88%B0L2%E6%AD%A3%E5%88%99.jpg)
```
假设先验概率为拉普拉斯分布，化简后目标函数后面出现L1-norm
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%85%88%E9%AA%8C%E5%88%B0L1%E6%AD%A3%E5%88%99.jpg)
```
对于任何模型，加入先验等同于目标函数加入正则
```

# Lasso/Ridge Regression 岭回归 特征筛选
```
样本个数小于数据特征维度，即需要特征选择

枚举法：
为了找到哪些特征更重要，列举出所有的特征组合，计算每种组合最后的accuracy，得到最好的特征组合，也就是最有用的特征

Greedy Approach:每一次都是当前局部的最优解
Forward Stepwise:
假设当前可选的特征为[f1,f2,f3,f4,f5]，通过对f单个循环找到最好的accuracy，假设是f2；剩下的可选特征为[f1,f3,f4,f5]，再通过计算{f1,f2},{f2,f3},{f2,f4},{f2,f5}最好的accuracy，假设是{f2,f4}；剩下的可选特征是[f1,f3,f5]，再计算{f1,f2,f4},{f2,f3,f4},{f2,f4,f5}找到最高的accuracy，发现还没原来的{f2,f4}高，那么停止算法，{f2,f4}就是最好的特征
Backward Stepwise:
假设当前可选的特征为[f1,f2,f3,f4,f5]，每次删掉一个特征计算{f1,f2,f3,f4},{f1,f2,f3,f5},{f1,f2,f4,f5},{f1,f3,f4,f5},{f2,f3,f4,f5}找到最高的accuracy，假设是{f1,f3,f4,f5}，当发现这个值比5个全选的accuracy还高，那么就确定当前的best_feature组合是{f1,f3,f4,f5}。然后再一次删掉一个特征，计算{f1,f3,f4},{f1,f3,f5},{f1,f4,f5},{f3,f4,f5}的accuracy，假设{f1,f3,f4}的accuracy最高，那么就确定当前的best_feature组合是{f1,f3,f4}。然后再依次删掉一个特征，发现每次的accuracy都比{f1,f3,f4}低，那么就可以确定{f1,f3,f4}是最好的特征组合。

via Regularization: 通过正则来筛选特征
Lasso Regression: 线性回归+L1-norm
岭回归：线性回归+L2-norm

但是Lasso回归有一个很大的问题，就是由于L1正则化项用的是绝对值之和，导致损失函数有不可导的点。也就是说，梯度下降法等优化算法对它统统失效了。
```

# Coordinate Descent 坐标下降法
```
坐标下降法是非梯度优化算法。与梯度优化算法沿着梯度最速下降的方向寻找函数最小值不同，坐标下降法依次沿着坐标轴的方向最小化目标函数值。
求f(x1,x2,x3,...,xn)的最小值时，分别求每个参数的偏导复杂，那么坐标下降法就是迭代地通过将大多数自变量固定（即看作已知常量），而只针对剩余的自变量f(x3)求极值的过程。
梯度下降法在图上是该点导数的切线方向，而坐标下降法是横平竖直的线。
假设f(x,y)=5x^2-6xy+5y，求(x,y)使目标函数最小
起始点（-0.5, -1.0），此时f =3.25，固定x，将f看成关于y的一元二次方程并求当f最小时y的值：
f(y|x=-0.5)=5y^2+3y+1.25
f'(y|x=-0.5)=10y+3 令其=0
y=-0.3
即，现在自变量的取值就更新成了（-0.5, -0.3）， f = 0.8
```
![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Coordinate_descent.svg/800px-Coordinate_descent.svg.png)

# Coordinate Descent for LASSO
```
目标函数为线性回归+L1-norm，令i为样本编号，令j为第j个特征
对第l个特征的权重求偏导数，先是复合函数求偏导，然后把全部的j遍历拆成等于l和不等于l的，然后展开乘法，令前面部分为Cl，后面为al成wl，al是平方和所以al大于0

因为L1-norm中wl存在绝对值，所以分三种情况讨论wl大于0 wl小于0 wl等于0。化简了绝对值之后令其偏导等于0，分别解出Cl和lamda之间的关系

不同于梯度下降，坐标下降偏导等于0求出来的值就是更新之后的值(参考上面例子)
所以依据上面三种情况，新的wl也分三类讨论，当满足Cl在中间时，wl的权值更新成0，也就是为什么LASSO之后会有很多特征的权值为0
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/LASSO%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/LASSO%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/LASSO%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D3.jpg)

# Optimization 优化 - Categories
```
识别问题种类：识别目标函数分类
1. Smooth vs non-Smooth：光滑的意思是各处都可以求导，不光滑是说存在不可导点，比如LASSO的原点
2. Convex vs non-convex：convex是说只有一个global全局最小点，而non-convex是说有很多local optimal局部最小点，比如深度学习
3. Discrete vs continuous：参数的选择是连续的还是只能选择几个点
4. constraint vs non-constraint：有没有such that的参数限制条件
然后就可以直接搜how to optimize/solve non-smooth non-convex continuous constraint problem

全局局部：如果是凸函数(图像像碗形)，那么找到的最小解一定是全局最小解，如果不是凸函数，那么就是局部最小解

要判断是不是凸函数
1. 定义法：首先判断定义域是不是凸集，再判断满足不满足凸函数定义
Convex Set(凸集)：任意x,y属于集合C,令a属于[0,1],如果有ax+(1-a)y也属于C，那么C是凸集。类似一个正多边形，其内部任意两点的连线还属于该多边形内部，那么就是个凸集
凸函数定义：当函数定义域为凸集，对于定义域内的任意xy都满足f(ax+(1-a)y) <= af(x)+(1-a)f(y)，那么就是凸函数
在图像上类似于开口向上的二次函数，任意两点画条线，线上的值都比原函数的值要大，那么二次函数就是凸函数

2. 一阶导数情况：
当f是一阶可导时，对任意xy都满足f(y) >= f(x)+f'(x)(y-x)时，则f为凸函数
在图像上类似于开口向上的二次函数，画出一点的切线及其向后的延长线，发现后面的函数值都大于该切线的值，那么二次函数是凸函数

3. 二阶可导情况：
当f是二阶可导时，对任意xy都满足f''(x) >= 0时，则f为凸函数
类比于画出二次函数的二阶导数图，从负无穷到正无穷单调递增，所以二次函数是凸函数

两个凸集的交集也是凸集
```

# Set Cover Problem
```
假设有个全集U以及m个子集S1,S2,...,Sm,目标是寻找数量最少的子集，使得这些子集的并集是等于U

1. 法一：穷举法
先遍历一遍只选择一个子集的情况，有没有能直接等于U的；
再遍历选择两个子集的并集的情况，看有没有两个的并集等于U的；
以次循环，直到找到最少子集的并集为U的情况
结果一定是全局最优解

2. 法二：贪心算法（只考虑当前步的最优解）
最初时刻的候选集为全部子集的并集，然后看这里面哪一个能去掉从而不影响结果(并集还是U)，去掉这一个子集之后再从里面继续找一个子集也去掉而不影响结果，以此循环，直到没法去掉任何一个子集
得到的结果可能不是全局最优解

3. 法三：目标函数推导优化
令xi为子集i是否被选择的标签
目标函数就是最小化所有子集标签的和
条件1是xi的选择只能是0或1
条件2是对于大集合U中的任意数字，都要保证所选出现这个数字的子集数量大于等于1
判断目标函数是不是convex凸函数，先看定义域是不是凸集，xi只能是0或者1，中间的数选不了，所以定义域不是凸集，那么目标函数是non-convex非凸函数
所以目标函数是Integer Linear Programming
使用relaxation把定义域改成[0,1]就可以使用Linear Programming solver
alpha-approximation：例如2-approximation就是全局最优解假设是2个子集，那么我的算法如果能达到小于等于2*2=4个，那么就认为这个近似算法还可以
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Set%20Cover%20Problem.jpg)

# Linear SVM
```
根据定义支持向量机定义，最大化向量边界间的距离。得到三个式子，两条边界的函数以及垂直于边界的法向量函数，化简之后就成了最大化2/||w||

1. Hard constraint
硬限制就是两个决策边界之间不能有任何点，目标函数就成了最小化||w||^2，在限制条件中把yi乘进来就变成了一个限制条件了

2. Soft constraint(slack variable -> εi)
软限制就是允许两个决策边界之间出现误差点，目标函数和限制条件都加上了一个可以接受的最大误差εi，当然想最小化εi了

Hinge Loss：把软限制的误差部分惩罚改成Hinge Loss，如果点在决策边界外面，说明没有cost，那么就产生0惩罚，如果乘积小于1，说明点在决策边界之间，是误差，那么就产生相应的惩罚，加到损失函数里。

使用随机梯度下降更新w和b，每遍历一个点，更新一次参数，如果点在决策边界外，只更新w，如果点在决策边界里，同时更新w和b
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SVM%20Hard%20constraint1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SVM%20Hard%20constraint2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SVM%20Soft%20constraint.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Soft%20constraint%20to%20Hinge%20Loss.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SGD%20for%20Hinge%20Loss.jpg)

# 增加特征维度
```
如果不能用直线划分两块点集，可能需要个曲线，Linear SVM就不行了。可以使用非线性模型如：神经网络，也可以把数据映射到一个高维度，在高维度上找到一条线一个线性模型来划分数据点集。

怎么映射高维度：假设当前X为(x1,x2)，然后定义一个非线性变换器Φ(X)=(x1^2,x2^2,sqrt(2)*x1*x2)，得到一个三个维度的新特征定义为U，然后就可以尝试用线性分类器来分许多个这种三个维度特征的点。
```

# 优化(KKT条件)
```
1. 等号条件
最小化f(x),有限制条件g(x)=0，那么定义新的最小化函数L=f(x)+λg(x)，然后分别对x的每个参数和λ求偏导令其等于0，得到最优解。
当有多个等号的限制条件时，对每个限制条件加个各自的λi然后加到L中，然后对x的每个参数以及每个λi求偏导令其等于0，得到最优解。

2. 不等号条件
当限制条件为不等号时，如果限制条件没起到作用，那么λ=0，h(x)<=0；如果限制条件起到作用，那么最优解一定在限制条件的决策边界上，即h(x)=0，λ>0。合并到一起就是λ*h(x)=0

3. 同时有等号条件和不等号条件(KKT条件)
新的目标函数同样是加上参数乘以限制条件，同时把不等号的限制条件更新为μ*h(x)=0

SVM的KKT条件：
把硬限制的SVM目标函数改成KKT条件的目标函数
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B8%80%E4%B8%AA%E7%AD%89%E5%8F%B7%E6%9D%A1%E4%BB%B6%E9%99%90%E5%88%B6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%A4%9A%E4%B8%AA%E7%AD%89%E5%8F%B7%E6%9D%A1%E4%BB%B6%E9%99%90%E5%88%B6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B8%8D%E7%AD%89%E5%8F%B7%E6%9D%A1%E4%BB%B6%E9%99%90%E5%88%B6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/KKT%E6%9D%A1%E4%BB%B6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SVM%E7%9A%84KKT%E6%9D%A1%E4%BB%B6.jpg)

# Dual Formulation(Kernel trick)
```
Primal to Dual：Primal问题有全局最优但是不好求，可以转换成Dual问题，但是只能求出局部最优解，就看两者之间的gap可不可以接受了。

对于KKT条件的SVM目标函数L，分别求L对w和b的偏导数令其等于0，把目标函数展开，带入偏导结果，再合并成新的Dual形式的目标函数。

Kernel trick就是增加维数变换+内积，K(x1,x2)=ϕ(x1)*ϕ(x2)=z1*z2
关键在于怎么定义ϕ函数变化
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SVM%20Primal%20to%20Dual.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E5%A2%9E%E5%8A%A0%E7%89%B9%E5%BE%81%E7%BB%B4%E5%BA%A6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/SVM%20Primal%20to%20Dual2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Kernel%20trick.jpg)