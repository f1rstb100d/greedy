# 数据结构
```
哈希表：传统按顺序遍历list是O(N)，把list里面每个值经过哈希运算得到索引编号，当再给定新的元素要去找的时候，先经过那个定义的哈希运算得到了它的索引编号，从而直接从list中拿出来，时间复杂度是O(1)。# Leetcode 242 15
搜索树：二叉树，对于每个节点，节点的左子树只包含小于当前节点的数，其右子树只包含大于当前节点的数。# Leetcode 98 22
堆：堆一定是一个完全二叉树(缺失元素只能是右子树，右下角元素)，最大堆是每个节点都比其子树所有节点大，最小堆是每个节点都比其子树所有节点小。 # Leetcode 347
```

# 交叉验证 cv Cross-Validation
```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

parameters = {'C':[0.001,0.01,0.1,0.5,1,2,5,10]}
lr = LogisticRegression
lr.fit(X_train,y_train).score(X_test,y_test)

clf = GridSearchCV(lr, parameters, cv=5)
clf.fit(X_train,y_train)
clf.score(X_test,y_test)
print(clf.best_params_)
```
```
以cv=5为例，对lamda可选的任何一个值，相当于给定lamda然后计算模型参数w和b，然后把这个模型用验证集计算准确率，重复5次计算一下5折交叉验证的准确率，取平均得到这个lamda的准确率，最后返回出准确率最高的那个超参数值，然后后续训练模型的参数时就可以人工指定这个超参数了
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.jpg)

# L2正则的作用
```
w1: minimize f(w1)  无正则
w2: minimize f(w2)+lamda||w2||2^2  有正则
w1的参数可选择范围为整个大参数空间，而w2仅被限制到了参数空间的一小部分
所以一定有f(w1)<=f(w2)，即w1更有可能找到更好的参数使得f结果更小
但不一定是越小越好，有可能存在过拟合
添加正则是防止过拟合的一种手段
```

# Grid Search
```
当同时使用L1-norm和L2-norm，就会有两个超参数lamda1和lamda2，两个超参数分别有一个各自的候选集，使用网格搜索遍历所有lamda1和lamda2的组合，使用交叉验证找到最好的(lamda1,lamda2)组合

除了Grid Search，其他一些参数搜索的方法：
1. 随机搜索(Random Search):超参数的可选项是一个范围，随机从范围中选出一个值作为这个超参数，然后把多个超参数组合作为这次交叉验证的参数。可以uniform等概率随机选择，也可以设定一个分布来随机选择超参数
2. 遗传算法(Genetic/Evolutionary Algorithm):若当前lamda值效果挺好的，那么下一个值就继承部分属性(遗传因子)；若效果不好就抛弃这个值
3. 贝叶斯优化(Bayesian Optimization):不断通过观测值调整先验概率，从而调整后验概率
```

# MLE与MAP
```
MLE(最大似然估计):仅通过观测值预测最好的参数theta
MAP(最大后验估计):通过观测值和先验概率去预测最好的参数theta
例：扔不规则硬币，扔了1w次，所以有可能先验概率(别人告我的概率)是不准确的，我可能会完全不相信，就看这1w次正反面得最后的概率
随着样本的增加，MLE比MAP更可信
当样本数据非常多的时候，MAP的解更趋近于MLE的解，因为先验概率在总和的占比原来越小，影响也就越来越小
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/MLE%E4%B8%8EMAP%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F.jpg)
```
假设先验概率为高斯分布正态分布，化简后目标函数后面出现L2-norm
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E9%AB%98%E6%96%AF%E5%85%88%E9%AA%8C%E5%88%B0L2%E6%AD%A3%E5%88%99.jpg)
```
假设先验概率为拉普拉斯分布，化简后目标函数后面出现L1-norm
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%85%88%E9%AA%8C%E5%88%B0L1%E6%AD%A3%E5%88%99.jpg)
```
对于任何模型，加入先验等同于目标函数加入正则
```