# 数据结构
```
哈希表：传统按顺序遍历list是O(N)，把list里面每个值经过哈希运算得到索引编号，当再给定新的元素要去找的时候，先经过那个定义的哈希运算得到了它的索引编号，从而直接从list中拿出来，时间复杂度是O(1)。# Leetcode 242 15
搜索树：二叉树，对于每个节点，节点的左子树只包含小于当前节点的数，其右子树只包含大于当前节点的数。# Leetcode 98 22
堆：堆一定是一个完全二叉树(缺失元素只能是右子树，右下角元素)，最大堆是每个节点都比其子树所有节点大，最小堆是每个节点都比其子树所有节点小。 # Leetcode 347
```

# 交叉验证
```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

parameters = {'C':[0.001,0.01,0.1,0.5,1,2,5,10]}
lr = LogisticRegression
lr.fit(X_train,y_train).score(X_test,y_test)

clf = GridSearchCV(lr, parameters, cv=5)
clf.fit(X_train,y_train)
clf.score(X_test,y_test)
print(clf.best_params_)
```
```
以cv=5为例，对lamda可选的任何一个值，计算一下5折交叉验证的准确率，返回出准确率最高的那个超参数值，然后后续训练模型的参数时就可以人工指定这个超参数了
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.jpg)