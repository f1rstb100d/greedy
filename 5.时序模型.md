# HMM(Hidden Markov Model)
```
下面的点是观测值x，上面的是latent variable隐藏值z。
HMM有三个参数θ=(A,B,Π)，其中A是转移矩阵，一般情况下z是离散型变量，假定z有m种选择，那么A转移矩阵就是m*m的矩阵，其中一位Aij表示当前一位z是i的情况下，下一位z是j的可能性有多少。B是生成矩阵，B形状是m*|v|(词库大小)，Bij就是当z是动词时生成单词work的可能性，动词是z的第i种可能性，work是词库中第j个单词。Π是由m个数字组成的向量，表示z1选择哪个作为初始的可能性。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20parameters.jpg)
```
HMM有两种问题分类，一种是Complete Case(x和z均为已知的)，另一种是Incomplete Case(只知道观测值x)，如何估计模型的三个参数。
Complete Case：直接基于统计去数每次以什么z的选择开头得到Π的向量值，A矩阵去数当前编号是1，下一个状态z是2的次数作为A12的值，B矩阵去数z为1是有多少次创造出了a作为B1a的值。
Incomplete Case：只知道x，不知道Z和θ，使用EM算法，循环估计Z和θ直到收敛。E-step求出Z的期望，M-step最大化lnp(X,Z|θ)
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Complete%20Case.jpg)
```
HMM的inference问题：假设给定θ=(A,B,Π)以及观测值x，想要找出最好的z
法一：全部遍历，假设z的可能取值有{a,b,c}，那么每个zi都有3种选择，列出所有的序列，评估每个序列的似然概率likelihood找到最高的，[p(z1)*p(z2|z1)*p(z3|z2)*...p(zn|zn-1)]*[p(x1|z1)*p(x2|z2)*...*p(xn|zn)]
法二：Viterbi算法，假设有n个z，每个z有m种选择，最好的Z的选择就是上面转移概率和生成概率乘积取最大值时的路径。δk(i)表示为最好路径在zk时选择第i个选项，那么就可以表示出在k+1时选择j的可能，也就是第k时的所有可能都会有一定的概率选择下一个点为j，选择这些的最大值。如何得到最好的序列：按时间顺序从左往右一次计算一列的值，直到最后一列，选出最后一列的最大值，然后根据当时逐步计算的历史记录往前反推路径是怎么来的(max值是前面哪个点得出的)。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20find%20Z%20Viterbi1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20find%20Z%20Viterbi2.jpg)
```
如何计算给定所有的观测值X，zk的概率？
把全部的x拆成两部分X1到Xk以及Xk+1到Xn，又因为X1:k与Xk+1:n是条件独立的，使用D-separate化简(删掉X1:k这个条件)，得到Backward和Forward乘积的结构。
Forward算法中先用边缘函数把Zk-1添加进来(所有Zk-1的和就是1)，然后拆成条件概率，其中的第二部分X1:k-1与Zk是条件独立(无关)的，即Zk的来源只和Zk-1有关，可以删掉；第三部分Xk只与Zk有关，里面的剩下的两个条件也可以删掉。然后就可以发现这是个递推公式乘A矩阵和B矩阵，也就可以用动态规划来做，还需要补充上初始Z1的计算公式Π和B矩阵的乘积。
Backward算法也类似，先把Zk+1加入公式，然后拆分条件概率，然后利用条件独立D-separate删掉一些条件，化简后得到动态规划的递推公式。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20FB%E7%AE%97%E6%B3%95.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20Forward%E7%AE%97%E6%B3%95.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20Backward%E7%AE%97%E6%B3%95.jpg)
```
EM算法：目标是MLE最大化似然概率，max p(X|θ)，假定θn是运算n次之后得到的最佳值(当作已知)，所以就max下一次与这一次的差即可，化简之后得到两部分E-step是求Z的期望(θ看作已知)，M-step求做好的θ(Z看作已知)。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/EM%E6%8E%A8%E5%AF%BC1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/EM%E6%8E%A8%E5%AF%BC2.jpg)
```
K-means同样也是使用EM算法，随机两个中心点，计算图中所有点分别到两个中心点的距离从而划分出来两个簇，然后重新计算两个簇的质心作为新的中心点，再计算每个点的距离重新划分簇，然后再重新计算每个簇的质心...以此循环，直到收敛，质心不再变化。
EM就是一步E，一步M，一直循环到收敛。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/K-means%20EM.jpg)
```
Estimate Π：
通过FB算法得到Z1取所有可能取值的expected count，然后相加得到总的count，最后均一化。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Estimate%20PI.jpg)
```
Estimate B：
使用FB算法得到在给定每个X的情况下，里面每个Z的所有可能取值的概率，然后相加构造B矩阵，看有多少由1生成a的值求和得到B1a，最后再按行均一化。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Estimate%20B.jpg)
```
Estimate A：
Bi-gram语言模型中取统计有多少个wj在wi后面占wi总个数的比例，即p(wj|wi)=c(wi,wj)/c(wi)
所以同理可以推导出当Zk=i时，下一个Zk+1是j的概率p(Zk+1=j|Zk=i)=p(Zk+1=j,Zk=i)/p(Zk=i)=C(Zk=i,Zk+1=j)/C(Zk=i)，其中的分母部分在给定X的情况下，使用Estimate B的FB算法就可以得到Zk=i的概率。剩下就需要计算分子部分，在给定X的情况下同时满足Zk=i和Zk+1=j的概率，下面化简后写作βk(i,j)
然后从头到尾挨个遍历每个生成的可能性，将加起来的值放到A矩阵的相应位置。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Estimate%20A1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Estimate%20A2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Estimate%20A3.jpg)

# CRF
```
Log Linear Model：产生逻辑回归和CRF
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/Log%20Linear%20Model.jpg)
```
多元逻辑回归
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E5%A4%9A%E5%85%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%921.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/%E5%A4%9A%E5%85%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%922.jpg)
```
CRF
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF2.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF3.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF4.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF5.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF6.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF7.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF8.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/CRF9.jpg)