# HMM(Hidden Markov Model)
```
下面的点是观测值x，上面的是latent variable隐藏值z。
HMM有三个参数θ=(A,B,Π)，其中A是转移矩阵，一般情况下z是离散型变量，假定z有m种选择，那么A转移矩阵就是m*m的矩阵，其中一位Aij表示当前一位z是i的情况下，下一位z是j的可能性有多少。B是生成矩阵，B形状是m*|v|(词库大小)，Bij就是当z是动词时生成单词work的可能性，动词是z的第i种可能性，work是词库中第j个单词。Π是由m个数字组成的向量，表示z1选择哪个作为初始的可能性。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20parameters.jpg)
```
HMM的inference问题：假设给定θ=(A,B,Π)以及观测值x，想要找出最好的z
法一：全部遍历，假设z的可能取值有{a,b,c}，那么每个zi都有3种选择，列出所有的序列，评估每个序列的似然概率likelihood找到最高的，[p(z1)*p(z2|z1)*p(z3|z2)*...p(zn|zn-1)]*[p(x1|z1)*p(x2|z2)*...*p(xn|zn)]
法二：Viterbi算法，假设有n个z，每个z有m种选择，最好的Z的选择就是上面转移概率和生成概率乘积取最大值时的路径。δk(i)表示为最好路径在zk时选择第i个选项，那么就可以表示出在k+1时选择j的可能，也就是第k时的所有可能都会有一定的概率选择下一个点为j，选择这些的最大值。如何得到最好的序列：按时间顺序从左往右一次计算一列的值，直到最后一列，选出最后一列的最大值，然后根据当时逐步计算的历史记录往前反推路径是怎么来的(max值是前面哪个点得出的)。
```
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20find%20Z%20Viterbi1.jpg)
![](https://github.com/f1rstb100d/greedy/blob/master/jpg/HMM%20find%20Z%20Viterbi2.jpg)